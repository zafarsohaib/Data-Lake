{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Testing Playground\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, LongType, DoubleType, IntegerType, DateType\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Test AWS Spark\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_data = \"data/log_data/*.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_log = spark.read.json(input_data).dropDuplicates()\n",
    "df_log.createOrReplaceTempView(\"log_table\")\n",
    "df_log.printSchema()\n",
    "df_log.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_log.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "song_data = \"data/song_data/*/*/*/*/*.json\"\n",
    "df_song = spark.read.json(song_data)\n",
    "df_song.createOrReplaceTempView(\"song_table\")\n",
    "df_song.printSchema()\n",
    "df_song.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_song.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_log = df_log[df_log['page'] == 'NextSong']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_log.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_songs = spark.sql(\"\"\"\n",
    "    select distinct song_id, title, artist_id, year, duration \n",
    "    from song_table\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_songs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_artists = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT artist_id, artist_name, artist_location, artist_latitude, artist_longitude\n",
    "        FROM ( SELECT artist_id, artist_name, artist_location, artist_latitude, artist_longitude,\n",
    "                row_number() over (partition by artist_id order by artist_name) as rown\n",
    "                from song_table\n",
    "                WHERE artist_id is not NULL)\n",
    "        WHERE rown=1\n",
    "\"\"\")\n",
    "df_artists.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_users = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT userId, firstName, lastName, gender, level\n",
    "        FROM ( SELECT userId, firstName, lastName, gender, level,\n",
    "                row_number() over (partition by userId order by ts desc) as rown\n",
    "                from log_table\n",
    "                WHERE page = 'NextSong' AND userId <> '')\n",
    "        WHERE rown=1\n",
    "\"\"\")\n",
    "df_users.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_users.write.parquet(\"output/users\", mode='overwrite')\n",
    "df_users2 = spark.read.parquet(\"output/users/*.parquet\")\n",
    "df_users2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "to_ts = F.udf(lambda x : datetime.utcfromtimestamp(int(x)/1000), TimestampType())\n",
    "df_log = df_log.withColumn(\"start_time\", to_ts(df_log.ts))\n",
    "\n",
    "df_log.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_log.createOrReplaceTempView(\"log_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_time = df_log.withColumn(\"hour\", F.hour(\"start_time\")) \\\n",
    "                .withColumn(\"day\", F.dayofmonth(\"start_time\")) \\\n",
    "                .withColumn(\"week\", F.weekofyear(\"start_time\")) \\\n",
    "                .withColumn(\"month\", F.month(\"start_time\")) \\\n",
    "                .withColumn(\"year\", F.year(\"start_time\")) \\\n",
    "                .withColumn(\"weekday\", F.dayofweek(\"start_time\"))\\\n",
    "                .select([\"start_time\", \"hour\", \"day\", \"week\", \"month\", \"year\", \"weekday\"]).dropDuplicates()\\\n",
    "df_time = df_time.withColumn(\"pk_year\", F.year(\"start_time\")).withColumn(\"pk_month\", F.month(\"start_time\"))\n",
    "df_time.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_time.write.partitionBy(\"pk_year\", \"pk_month\").parquet(\"output/time\", mode='overwrite')\n",
    "df_time2 = spark.read.parquet(\"output/time/*/*/*.parquet\")\n",
    "df_time2.count()\n",
    "df_time2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_songplay = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT se.start_time, se.userId as user_id, se.level, ss.song_id, \n",
    "    ss.artist_id, se.sessionId as session_id, se.location, se.userAgent as user_agent\n",
    "    FROM log_table se\n",
    "    inner join song_table ss on (ss.artist_name = se.artist AND ss.title = se.song)\n",
    "    where se.page = 'NextSong'\n",
    "\"\"\").withColumn(\"songplay_id\", F.monotonically_increasing_id())\n",
    "df_songplay.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_songplay.write.parquet(\"output/songplay\", mode='overwrite', partitionBy=[\"userId\", \"sessionId\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_songplay_par = spark.read.parquet(\"output/songplay/*/*/*.parquet\")\n",
    "df_songplay_par.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_songplay_par.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_songplay_par.select(\"*\").where(df_songplay_par.level=='n').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_time.createOrReplaceTempView(\"time_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_songplay = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT se.start_time, se.userId as user_id, se.level, ss.song_id, \n",
    "    ss.artist_id, se.sessionId as session_id, se.location, se.userAgent as user_agent,\n",
    "    t3.year, t3.month\n",
    "    FROM log_table se\n",
    "    inner join song_table ss on (ss.artist_name = se.artist AND ss.title = se.song)\n",
    "    left join time_table t3 on t3.start_time = se.start_time \n",
    "    where se.page = 'NextSong'\n",
    "\"\"\").withColumn(\"songplay_id\", F.monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_songplay.write.parquet(\"output/songplay\", mode='overwrite', partitionBy=[\"year\", \"month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_sp_par = spark.read.parquet(\"output/songplay/*/*/*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_sp_par.withColumn(\"month\", F.month(\"start_time\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_sp_par.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_sp_par.createOrReplaceTempView(\"songplays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songplays_table = spark.sql(\"\"\"\n",
    "            select distinct t1.start_time, t1.userId as user_id, t1.level, t2.song_id, \n",
    "            t2.artist_id, t1.sessionId as session_id, t1.location, t1.userAgent as user_agent\n",
    "            from log_table t1\n",
    "            inner join song_table t2 on (t2.artist_name = t1.artist AND t2.title = t1.song)\n",
    "            where t1.page = 'NextSong'\n",
    "            \"\"\") \\\n",
    "        .withColumn(\"songplay_id\", F.monotonically_increasing_id()) \\\n",
    "        .withColumn(\"year\", F.year(\"start_time\")) \\\n",
    "        .withColumn(\"month\", F.month(\"start_time\"))\n",
    "songplays_table.show()\n",
    "songplays_table.write.parquet(\"output/songplay\", mode='overwrite', partitionBy = [\"year\", \"month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "p_someplay = spark.read.parquet(\"output/songplay/*/*/*.parquet\")\n",
    "p_someplay.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "p_someplay = spark.read.parquet(\"output/songplay/*/*/*.parquet\")\n",
    "p_someplay.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "p_someplay = spark.read.parquet(\"output/songplay/*/*/*.parquet\")\n",
    "p_someplay.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "p_users = spark.read.parquet(\"output/users/*.parquet\")\n",
    "p_users.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "p_songs = spark.read.parquet(\"output/songs/*.parquet\")\n",
    "p_songs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "p_artists = spark.read.parquet(\"output/artists/*.parquet\")\n",
    "p_artists.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "p_time = spark.read.parquet(\"output/time/*/*/*.parquet\")\n",
    "p_time.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "p_users.select([\"first_name\", \"last_name\"]).where(p_users.level=='paid').orderBy(p_users.first_name).limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "p_someplay.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = p_someplay.join(p_users, on=['user_id'], how='inner').join(p_songs, on=['song_id'], how='inner')\n",
    "df.select([\"first_name\", \"last_name\"]).where(df.title=='Setanta matins').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
